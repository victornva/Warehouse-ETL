##############################################################################################################
# Урок 7
# Great Expectations 
##############################################################################################################

создадим для хранения метаданных таблицы с логами и статистикой в целевом постгресе:

# \c dstdb
You are now connected to database "dstdb" as user "root".
dstdb=# create table log (
dstdb(#        source_launch_id    int
dstdb(#      , target_schema       text
dstdb(#      , target_table        text
dstdb(#      , target_launch_id    int
dstdb(#      , processed_dttm      timestamp default now()
dstdb(#      , row_count           int
dstdb(#      , duration            interval
dstdb(#      , load_date           date
dstdb(# );
CREATE TABLE
dstdb=# create table statistic (
dstdb(#        table_name     text
dstdb(#      , column_name    text
dstdb(#      , cnt_nulls      int
dstdb(#      , cnt_all        int
dstdb(#      , load_date      date
dstdb(# );
CREATE TABLE
dstdb=# \dt
         List of relations
 Schema |   Name    | Type  | Owner
--------+-----------+-------+-------
 public | customer  | table | root
 public | log       | table | root
 public | statistic | table | root
 
Дополнительные поля в нашем хранилище (у всех таблиц):

• launch_id (уникальный идентификатор таска)
• effective_dttm (дата загрузки, default now()) 
 
dstdb=# ALTER TABLE public.customer ADD launch_id varchar NULL;
dstdb=# ALTER TABLE public.customer ADD effective_dttm date NULL DEFAULT now();

docker cp ./data_transfer.py airflow:/usr/local/lib/python3.7
docker cp ./utils.py airflow:/usr/local/lib/python3.7

delete from customer;

PS C:\Distrib\GB\ХД&ETL\Lesson-7> docker cp ./utils.py airflow:/usr/local/lib/python3.7
PS C:\Distrib\GB\ХД&ETL\Lesson-7> docker cp ./data_transfer_ge.py airflow:/usr/local/lib/python3.7
PS C:\Distrib\GB\ХД&ETL\Lesson-7> docker cp ./postgres_ge.py airflow:/usr/local/lib/python3.7
docker cp ./dag_ge.py airflow:/usr/local/airflow/dags








